{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hazardous-feelings",
   "metadata": {},
   "source": [
    "## *Towards Deep Understanding: An Introductory Tutorial on Causal Inference*\n",
    "\n",
    "#### [Serbian Machine Learning Workshop](https://workshops.eeml.eu/) part of the [EEML](https://www.eeml.eu/home) Workshop Series 2022\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "####### **Presenter:** [Matej Zečević](https://scholar.google.com/citations?user=gzJZcPUAAAAJ&hl=en) from the [AI & ML Lab at TU Darmstadt, Germany](https://ml-research.github.io/)\n",
    "\n",
    "Feel free to visit: [matej-zecevic.de](https://matej-zecevic.de) for open-access articles on science and culture. This Code Tutorial will also be uploaded there after the live event at SMLW.\n",
    "\n",
    "**Abstract:** In this practical session the attendee is going to explore concepts from causality in the formalized notion from Turing award winner Judea Pearl (key reference here is the book \"Causality\" 2009 Cambridge University Press, but we will also explore notions from subsequent literature as in \"Elements of Causal Inference \" 2017 from Peters et al. in MIT Press) in a machine learning context. These concepts involve reasoning about causal relations themselves (known as causal discovery) but also reasoning about causal effects (known as causal identification/estimation). To succeed in such an endeavour it takes not only data but also assumptions (or inductive biases) that can alleviate inference to reason about true causal relations exposed by the system under investigation, as famously put by Pearl himself the community must go beyond current machine learning which \"amounts to only curve fitting\". We will explore examples that make clear why this arguably harsh sentiment towards current practices in deep learning can find justification in formulable notions that make apparent why and how the field might continue to evolve towards the original dream of artificial intelligence. The attendee must not be afraid of exploring this growing field at the intersection of causality and machine learning at new since this practical will allow to follow from the ground-up with simple examples, yet leave room for discussions regard cutting edge research revolving around modern models such as graph neural networks and a couple of examples of advanced topics. The attendee will learn to recognize that deep learning has the potential to evolve towards deep understanding and hopefully this practical will motivate to engage in a community effort towards causal machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-generic",
   "metadata": {},
   "source": [
    "### Table of Content:\n",
    "\n",
    "* **[1] On Why We Need Causality**\n",
    "* **[2] Introducing Elements of Causal Reasoning**\n",
    "    * [2.1] Consequence of Pearl's Causal Hierarchy\n",
    "    * [2.2] Our Causal Representation of Choice: The Structural Causal Model\n",
    "* **[3] How do we get the Graph? Onto Causal Discovery!**\n",
    "* **[B] Bonus: We have the Graph. What do we do with it?**\n",
    "    * [B.1] Complimenting the $do$-Calculus with Neural Networks\n",
    "    * [B.2] Bounding Causal Effects from Causal Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-april",
   "metadata": {},
   "source": [
    "Recommendation of Literature/References for Self-Study:\n",
    "* Judea Pearl, [“Causality”](http://bayes.cs.ucla.edu/BOOK-2K/), Cambridge University Press, 2009.\n",
    "* Peters et al., [“Elements of Causal Inference”](https://mitpress.mit.edu/books/elements-causal-inference), MIT Press, 2017.\n",
    "* Jonas Peters [Lecture Series “Causality” on YouTube](https://www.youtube.com/watch?v=zvrcyqcN9Wo), MIT, 2017.\n",
    "* Brady Neal’s [Online Course ”Introduction to Causal Inference”](https://www.bradyneal.com/causal-inference-course), 2020. \n",
    "* Elias Bareinboim [Lecture “Causal Data Science” on YouTube](https://www.youtube.com/watch?v=dUsokjG4DHc), 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-liverpool",
   "metadata": {},
   "source": [
    "Since this tutorial provides code, we will have to use several libraries to help us compile the content of this tutorial and fix some preliminary setting. Below is the full set of dependencies, each explained via a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "native-treasure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# libraries for maths and data structures\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# some general libraries\n",
    "import utils\n",
    "from string import ascii_uppercase\n",
    "\n",
    "# visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# base settings for the plots and for reproducibility\n",
    "sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\n",
    "sns.set_palette(\"cubehelix\")\n",
    "np.random.seed(70522)\n",
    "random.seed(70522)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-charm",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "german-ratio",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "greek-inventory",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "integrated-qualification",
   "metadata": {},
   "source": [
    "### [1] On Why We Need Causality\n",
    "\n",
    "On a simple example we will make clear why the Pearlian notion of Causality is crucial for next-generation learning systems, which we require to reason about settings outside their \"comfort zone\" i.e., outside the available data or in scenarios similar yet distinct of what is known.\n",
    "\n",
    "The following example is based on Peters et al. 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-bedroom",
   "metadata": {},
   "source": [
    "First, we load our data set which contains 200 samples of activities of two genes $A$ and $B$ recorded alongside a phenotype $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset-Example-Phenotype-and-Genes.csv\", index_col=0)\n",
    "df[[\"gene_A\", \"gene_B\", \"phenotype\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-remains",
   "metadata": {},
   "source": [
    "Let's now visualize the data to get a first feel of which relations are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(10,7))\n",
    "\n",
    "x='gene_A'\n",
    "y='phenotype'\n",
    "sns.scatterplot(data=df, x=x, y=y, ax=axs[0])\n",
    "axs[0].set_yticks(np.arange(0-5, 15+5, 5.0))\n",
    "axs[0].set_xticks(np.arange(0-2, 8+2, 2.0))\n",
    "axs[0].set_aspect(1./axs[0].get_data_ratio())\n",
    "\n",
    "x='gene_B'\n",
    "y='phenotype'\n",
    "sns.scatterplot(data=df, x=x, y=y, ax=axs[1])\n",
    "axs[1].set_yticks(np.arange(0-5, 15+5, 5.0))\n",
    "axs[1].set_xticks(np.arange(0-2, 8+2, 2.0))\n",
    "axs[1].set_aspect(1./axs[1].get_data_ratio())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-manner",
   "metadata": {},
   "source": [
    "We clearly observe a strong correlation between both $(A,P)$ and $(B,P)$.\n",
    "\n",
    "Let's fit a simple machine learning model (Linear Regression) to our data now such that we can flexibly predict arbitrary inputs. \n",
    "\n",
    "Therefore, let's also visualize said model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(fit_intercept=False) for i in range(2)]\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,7), sharex='col', sharey='row')\n",
    "\n",
    "for ind, x in enumerate(['gene_A', 'gene_B']):\n",
    "    \n",
    "    features = df[x][:,np.newaxis]\n",
    "    targets = df[y]\n",
    "    models[ind].fit(features, targets)\n",
    "    prediction_intervall = np.arange(0-2, 8+2, 0.05)[:,np.newaxis]\n",
    "    predictions = models[ind].predict(prediction_intervall)\n",
    "    \n",
    "    sns.scatterplot(data=df, x=x, y=y, ax=axs[ind])\n",
    "    axs[ind].plot(prediction_intervall, predictions)\n",
    "    axs[ind].set_yticks(np.arange(0-5, 15+5, 5.0))\n",
    "    axs[ind].set_xticks(np.arange(0-2, 8+2, 2.0))\n",
    "    axs[ind].yaxis.set_tick_params(labelbottom=True)\n",
    "    axs[ind].set_box_aspect(1.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-identity",
   "metadata": {},
   "source": [
    "Great. We have a model of our data now, and looking at the fit, we have found the bist linear model for the job.\n",
    "\n",
    "#### Question Time\n",
    "\n",
    "We want to find out more about the relation between $A, B$ and $P$. Therefore, we decide to conduct two experiments in the biology lab that initially collected our data, since they have the capabilities to do so. The experiments will set each the activity of a gene to zero (we will denote this with $do(A=0)$ and $do(B=0)$) and record the data for us, respectively.\n",
    "\n",
    "**Q: What can we expect from such an experimental setup?**\n",
    "\n",
    "**A:** Well, we have a trained machine learning model. Why not just ask it what it thinks on the input $A=0$?\n",
    "\n",
    "Therefore, in both cases we'd expect the value predicted by our two models when we set our input to 0 i.e., $f(0)$ where $f$ is our learned model --- which in this case evaluates to approx. 0 in both cases.\n",
    "\n",
    "Our answer, we expect the phenotype to react to our experiments and become 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pool1 = pd.read_csv(\"Dataset-Example-Phenotype-and-Genes-Pool-1.csv\") # loading newly collected experimental data\n",
    "df_pool2 = pd.read_csv(\"Dataset-Example-Phenotype-and-Genes-Pool-2.csv\")\n",
    "\n",
    "dfs = [df_pool1, df_pool2]\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,7), sharex='col', sharey='row')\n",
    "for ind, x in enumerate(['gene_A', 'gene_B']):\n",
    "    \n",
    "    features = df[x][:,np.newaxis]\n",
    "    targets = df[y]\n",
    "    models[ind].fit(features, targets)\n",
    "    prediction_intervall = np.arange(0-2, 8+2, 0.05)[:,np.newaxis]\n",
    "    predictions = models[ind].predict(prediction_intervall)\n",
    "    \n",
    "    sns.scatterplot(data=dfs[ind], x=x, y=y, ax=axs[ind], hue='distribution')\n",
    "    axs[ind].plot(prediction_intervall, predictions)\n",
    "    axs[ind].set_yticks(np.arange(0-5, 15+5, 5.0))\n",
    "    axs[ind].set_xticks(np.arange(0-2, 8+2, 2.0))\n",
    "    axs[ind].yaxis.set_tick_params(labelbottom=True)\n",
    "    axs[ind].set_box_aspect(1.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-touch",
   "metadata": {},
   "source": [
    "Well, this is unexpected.. (not in the scope of this presentation, but as a genuine result.)\n",
    "\n",
    "The experimental results provided to us hold accurately in one case but are *completely off in the other*.\n",
    "\n",
    "The question arises **Why?** (this might also be one of the reasons J. Pearl named his 2018 book \"The Book of Why\".)\n",
    "\n",
    "\n",
    "**We conclude that machine learning using *only data* is not sufficient, even in this simple setting - we could not have predicted correctly, the only correct answer was \"I don't know\". Therefore, we need to go *beyond*!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-steel",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "empirical-diana",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "exposed-doctrine",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "simple-haven",
   "metadata": {},
   "source": [
    "### [2] Introducing Elements of Causal Reasoning\n",
    "\n",
    "One possible explanation for what we just observed in the previous section is that the underlying data generating process (i.e., the physical reality that governs the relation of $A, B$ and $P$) is somehow different between the two pairs $(A,P)$ and $(B,P)$ in that $A$ changes $P$ but $B$ does not change $P$.\n",
    "\n",
    "Such a notion of *change* is what is being captured by the Pearlian notion of Causality.\n",
    "\n",
    "I.e., we say $A$ causes $P$ but $B$ does not cause $P$.\n",
    "\n",
    "Now, you might ask, how did they corrolate ($B$ and $P$) so strongly in the first place?\n",
    "\n",
    "Well, the simple answer is, that $B$ and $P$ are affected by a common cause, a (hidden) *confounder*.\n",
    "\n",
    "Graphically, we can depict this intution as\n",
    "$$\n",
    "A\\rightarrow P\n",
    "$$\n",
    "and\n",
    "$$\n",
    "B\\leftarrow C \\rightarrow P\n",
    "$$\n",
    "where $C$ is said hidden confounder. (Hidden, because we only now started hypothesizing that it must exist.)\n",
    "\n",
    "To summarize, we needed to go \"outside\" our data and model choice to the *assumptions* over what generated our data, to finally come up with a distinction of the previous two settings, which otherwise looked indiscernible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-illness",
   "metadata": {},
   "source": [
    "#### [2.1] Consequence of Pearl's Causal Hierarchy\n",
    "\n",
    "The experiments that we have conducted (or rather the biology lab) are known as *interventions* in causality.\n",
    "\n",
    "And by observing this interventional data, we were able to conclude the graphs underlying our data.\n",
    "\n",
    "Let's try to capture this idea from ground-up, with simple toy data that we will generate ourselves.\n",
    "\n",
    "We will call this \"base\" data, *observational* data.\n",
    "\n",
    "Let\n",
    "$$\n",
    "A = U_A\n",
    "$$\n",
    "and\n",
    "$$\n",
    "B = A \\wedge U_B\n",
    "$$\n",
    "with $\\wedge$ being logical and, and $U_A,U_B$ be independent and identically distributed, say, just a random, fair coin flip $\\mathcal{B}(0.5)$.\n",
    "\n",
    "We use $U$ to denote something \"**U**nmodelled\" (things we forgot, don't know about or simply see as noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_data(N):\n",
    "    \"\"\"\n",
    "        N is the number of samples\n",
    "    \"\"\"\n",
    "    U_A = np.random.binomial(1,.5,(N,1))\n",
    "    U_B = np.random.binomial(1,.5,(N,1))\n",
    "    A = U_A\n",
    "    B = np.logical_and(A, U_B)\n",
    "    return np.hstack((A, B))\n",
    "\n",
    "print(\"Toy SCM is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-interstate",
   "metadata": {},
   "source": [
    "Let's simulate our data now by sampling the noise terms and instantiating them.\n",
    "\n",
    "This gives us our observational distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(toy_data(N=10000), columns=[\"A\",\"B\"])\n",
    "\n",
    "print(f\"Var(A)={np.var(df['A']):.2f}, Var(B)={np.var(df['B']):.2f},\")\n",
    "\n",
    "sns.barplot(data=df)\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Observational probabilities P(A=1) and P(B=1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-diversity",
   "metadata": {},
   "source": [
    "As expected, $P(A)=0.5$, whereas $P(B)=0.25$ since we can see it as two subsequent fair coin flips.\n",
    "\n",
    "Now, as before, we would like to do an experiment, an intervention, but this time *we control the data*, so to perform an intervention $do(A=1)$ we simply \"hardcode\" $A$ to be assigned $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_data_int_A(N):\n",
    "    \"\"\"\n",
    "        N is the number of samples\n",
    "    \"\"\"\n",
    "    U_A = np.random.binomial(1,.5,(N,1))\n",
    "    U_B = np.random.binomial(1,.5,(N,1))\n",
    "    A = np.ones((N,1))\n",
    "    B = np.logical_and(A, U_B)\n",
    "    return np.hstack((A, B))\n",
    "\n",
    "df_int_A = pd.DataFrame(toy_data_int_A(N=10000), columns=[\"A\",\"B\"])\n",
    "\n",
    "print(f\"Var(A)={np.var(df_int_A['A']):.2f}, Var(B)={np.var(df_int_A['B']):.2f},\")\n",
    "\n",
    "sns.barplot(data=df_int_A)\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Interventional probabilities P(A=1|do(A=1)) and P(B=1|do(A=1))\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-impression",
   "metadata": {},
   "source": [
    "As expected, since $A$ changed and $A$ is a cause of $B$ by definition, we see a change in $B$ i.e., $P(B|do(A=1))=0.5$.\n",
    "\n",
    "Interestingly, this intervention coincides with the *conditional* probability distribution $p(B|A=1)$ which we get by rules of probability theory $p(B|A)=\\frac{p(A,B)}{p(A)}$ i.e., we simply look at all $B$'s where $A=1$. (Note, that decimal differences are due to sampling, in the limit of $N\\rightarrow \\infty$ samples we will have equality.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Conditional Probability P(B=1|A=1)={sum(df.iloc[np.where(df[\"A\"]==1)][\"B\"])/len(df.iloc[np.where(df[\"A\"]==1)]):.2f}')\n",
    "print(f'Interventional Probability P(B=1|do(A=1))={sum(df_int_A[\"B\"])/len(df_int_A):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-intelligence",
   "metadata": {},
   "source": [
    "Generally, interventions are different from observations and thus conditioning (i.e., the above example was a special case since $A$ is the only cause of $B$) as this simple example where we intervene on $B$ shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_data_int_B(N):\n",
    "    \"\"\"\n",
    "        N is the number of samples\n",
    "    \"\"\"\n",
    "    U_A = np.random.binomial(1,.5,(N,1))\n",
    "    U_B = np.random.binomial(1,.5,(N,1))\n",
    "    A = U_A\n",
    "    B = np.ones((N, 1))\n",
    "    return np.hstack((A, B))\n",
    "\n",
    "df_int_B = pd.DataFrame(toy_data_int_B(N=10000), columns=[\"A\",\"B\"])\n",
    "\n",
    "print(f\"Var(A)={np.var(df_int_B['A']):.2f}, Var(B)={np.var(df_int_B['B']):.2f},\")\n",
    "\n",
    "sns.barplot(data=df_int_B)\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Interventional probabilities P(A=1|do(B=1)) and P(B=1|do(B=1))\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Conditional Probability P(A=1|B=1)={sum(df.iloc[np.where(df[\"B\"]==1)][\"A\"])/len(df.iloc[np.where(df[\"B\"]==1)]):.2f}')\n",
    "print(f'Interventional Probability P(A=1|do(B=1))={sum(df_int_B[\"A\"])/len(df_int_B):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-virtue",
   "metadata": {},
   "source": [
    "As predicted, $P(B|A)\\neq P(B|do(A))$ since in the former we observe $B$ (i.e., the noise terms $U_i$ get instantiated and thus fixed) whereas in the latter we actually change the cause of $B$ by deciding that it now corresponds to a constant. The graph changes thus to the disconnected graph\n",
    "$$\n",
    "A \\not\\rightarrow B.\n",
    "$$\n",
    "\n",
    "So, knowing $B$ was $1$ implies that $A$ was also $1$ whereas setting $B$ to $1$ renders $B$ independent of $A$.\n",
    "\n",
    "To summarize, we can ask these questions:\n",
    "\n",
    "* **Q1 (observational):** What is the probability of $B$ being $1$, formally $P(B=1)$?\n",
    "* **Q2 (conditional):** I know that $A$ is 1, so how does this change my belief in $B$ being $1$, formally $P(B=1|A=1)$?\n",
    "* **Q3 (interventional):** We have done an experiment where we set $A$ to 1, what is our belief in $B$ being $1$, formally $P(B=1|do(A=1))$?\n",
    "\n",
    "As you might have thought of yourself, we can also combine Q2 and Q3 to form a third type of reasoning, that is, we might ask *retrospectively*:\n",
    "\n",
    "**Q4 (counterfactual)** We have seen both $A,B$ being 0, but if we had changed $B$ to $1$ what are the chances $A$ would have been $1$, formally $P(A=0|do(B=1),A=1,B=0)$?\n",
    "\n",
    "To give an example for Q4, imagine $A=1$ denoting having a headache and $B=1$ denoting taking an aspirin, then Q4 essentially asks whether we would have cured our headache if we had taken the aspirin since we actually ended up having headache after not taking an aspirin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-question",
   "metadata": {},
   "source": [
    "![Pearl's Causal Hierarchy](PCH.pbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-crash",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "automated-horizontal",
   "metadata": {},
   "source": [
    "#### [2.2] Our Causal Representation of Choice: The Structural Causal Model\n",
    "\n",
    "In the last section, we took control in our hand and discovered the different notions of reasoning (observational, interventional, counterfactual) from ground-up. Actually, we also used already our representation of choice --- the **Structural Causal Model**, SCM for short.\n",
    "\n",
    "The description of how $A, B$ are computed are known as structural equations.\n",
    "\n",
    "More formally, we have an SCM given by\n",
    "\n",
    "$$\n",
    "\\mathcal{M}=\\langle \\mathbf{V}, \\mathbf{U}, \\mathcal{F}, P(\\mathbf{U}) \\rangle\n",
    "$$\n",
    "\n",
    "where $\\mathbf{V}$ are our endogenous (observed) variables (e.g. $\\mathbf{V}=\\{A,B\\}$)\n",
    "\n",
    "where $\\mathbf{U}$ are our exogenous (hidden) variables (e.g. $\\mathbf{U}=\\{U_A,U_B\\}$)\n",
    "\n",
    "where $\\mathcal{F}$ are our structural equations (e.g. $\\mathcal{F}=\\{f_A(U_A)=U_A,f_B(A,U_B)=A+U_B\\}$)\n",
    "\n",
    "and finally where $P(\\mathbf{U})$ is a product distribution (our $\\mathbf{U}$ are independent).\n",
    "\n",
    "Again, remember that this is nothing new --- we already discovered it, it just the general formulation!\n",
    "\n",
    "Also, remember that $\\mathcal{M}$ implies a graph structure $G:=G(\\mathcal{M})$, which in the cases we consider here, we can simply read off from the structural equations in $\\mathcal{F}$.\n",
    "\n",
    "For example, as before, let $\\mathcal{M}=\\langle \\{A,B\\}, \\{U_A,U_B\\}, \\{f_A(U_A)=U_A,f_B(A,U_B)=A+U_B\\}, \\mathcal{B}(0.5)*\\mathcal{B}(0.5) \\rangle$ the graph is\n",
    "\n",
    "$$\n",
    "A\\rightarrow B\n",
    "$$\n",
    "\n",
    "**To conclude, the SCM represents our causal system and it is more than just a graph, it is actually a *simulator* that can generate our data and by that implies a graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-secret",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "olive-original",
   "metadata": {},
   "source": [
    "### [3] How do we get the Graph?\n",
    "\n",
    "This is the question of concern now. \n",
    "\n",
    "We have seen in Section [1] why causality is needed in machine learning by observing a hopeless situation, where regular machine learning fails.\n",
    "\n",
    "We have seen in Section [2] all key elements of reasoning, and how they connect to what we already know from regular probability theory.\n",
    "\n",
    "But now that we know what an SCM is, how do we get it, or *how do we even get only the graph?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-beatles",
   "metadata": {},
   "source": [
    "In the following, we will use show the application of two different methods from the causal discovery literature.\n",
    "\n",
    "* The first algorithm comes from the family of constraint-based methods. The first ever proven both sound and complete causal discovery algorithm, **Fast Causal Inference** (Spirtes et al., 2000), FCI for short. FCI works both fast and gives guarantees, however, comes at the lack of being able to discern graphs which share a notion of equivalence (i.e., we usually won't get the exact, unique graph of our problem at hand).\n",
    "\n",
    "  The algorithm exploits *conditional independences* found in the data to construct the graph by adhering to what is known as $d$-separation, a graphical criertion which establishes an equivalence to the former by the Markov condition and faithfulness, formally $A \\underset{P}{\\perp} B | C \\iff A \\underset{G}{\\perp} B | C$ where an independence in $P$ is equivalent to a separation in graph $G$. \n",
    "\n",
    "Be assured, we need not go in the details here, but we will simply explore our original biology example using FCI.\n",
    "\n",
    "* The second algorithm is a more recent one that disconnects from causal guarantees (i.e., is really concerned with evaluating sensible structures) but is very effective, NOTEARS (Zheng et al. 2018), NT for short. Unfortunately, the algorithm scales cubically in the number of dimensions $d, \\mathcal{O}(d^3)$ rendering it restrictive but it offers a complete continuous-optimization characterization of the structure learning problems.\n",
    "\n",
    "  The algorithm optimizes the mean-squared error (MSE) over DAGs, where a DAG is guaranteed via convergence to an acylicity constraint.\n",
    "\n",
    "Again, be assured, we need not go in the details here, but we will also explore our original biology example using NT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hundred-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causallearn.search.ConstraintBased.FCI import fci\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from linear import notears_linear\n",
    "\n",
    "def graph_induction(D, method):\n",
    "\n",
    "    if method == \"notears\":\n",
    "        G_pred = notears_linear(D, lambda1 = .1, loss_type = 'l2')\n",
    "    elif method == \"fci\":\n",
    "        G_pred = fci(D, verbose=False)\n",
    "        G_pred = G_pred[0].graph\n",
    "\n",
    "    return G_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-sally",
   "metadata": {},
   "source": [
    "Let's load our data again. Note that we are going to only look at our observational data i.e., the data which originally did not help us discern the causal system, since we did not ask for a causal model. That is, we will try to find the true causal graph of $B\\leftarrow C\\rightarrow P$ just from data points. This time around we will asumme that we observe the confounder $C$ (but we don't know yet whether it is actually a confounder, since of course, we want to know the graph now).\n",
    "\n",
    "We will consider an alternate version of our data set in which we know the underlying functions to be non-linear, this will render our causal structure *identifiable*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "orange-trader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confounder</th>\n",
       "      <th>gene_B</th>\n",
       "      <th>phenotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.537672</td>\n",
       "      <td>-0.155436</td>\n",
       "      <td>-0.536190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.208107</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.228719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979998</td>\n",
       "      <td>0.941186</td>\n",
       "      <td>1.602635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.277776</td>\n",
       "      <td>11.817702</td>\n",
       "      <td>2.287479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.212762</td>\n",
       "      <td>1.783719</td>\n",
       "      <td>3.323583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.991889</td>\n",
       "      <td>-0.975865</td>\n",
       "      <td>-0.597651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.609639</td>\n",
       "      <td>0.226578</td>\n",
       "      <td>0.890405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.201669</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>2.279240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.676270</td>\n",
       "      <td>-0.309287</td>\n",
       "      <td>-0.595883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-1.358918</td>\n",
       "      <td>-2.509456</td>\n",
       "      <td>-1.073984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     confounder     gene_B  phenotype\n",
       "0     -0.537672  -0.155436  -0.536190\n",
       "1      0.208107   0.009013   0.228719\n",
       "2      0.979998   0.941186   1.602635\n",
       "3      2.277776  11.817702   2.287479\n",
       "4      1.212762   1.783719   3.323583\n",
       "..          ...        ...        ...\n",
       "995   -0.991889  -0.975865  -0.597651\n",
       "996    0.609639   0.226578   0.890405\n",
       "997    0.201669   0.008202   2.279240\n",
       "998   -0.676270  -0.309287  -0.595883\n",
       "999   -1.358918  -2.509456  -1.073984\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset-Example-Phenotype-and-Genes-Nonlinear.csv\")\n",
    "\n",
    "df = df.loc[:,[\"confounder\", \"gene_B\", \"phenotype\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = df.to_numpy()\n",
    "\n",
    "G_pred_fci = graph_induction(D, method=\"fci\")\n",
    "G_pred_nt = graph_induction(D, method=\"notears\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = len(df.columns)\n",
    "dict_visualization = {\n",
    "    \"Fast Causal Inference Algorithm\": G_pred_fci,\n",
    "    \"NOTEARS Algorithm\": G_pred_nt,\n",
    "}\n",
    "\n",
    "sharex = sharey = True\n",
    "experiment_description = f'''\n",
    "Inferring the Causal Graph of our Biology Data Set from purely Observational Data\\n\n",
    "Top Row shows FCI/NT predicted graph as an adjacency matrix,\n",
    "Bottom Row shows the actual graph\n",
    "'''\n",
    "suptitle = f'{experiment_description}'\n",
    "\n",
    "commonlabel = list(df.columns)\n",
    "utils.plot_all_individual(list(dict_visualization.values()),\n",
    "                    list(dict_visualization.keys()),\n",
    "                    suptitle=suptitle,\n",
    "                    alt_form=(1,2),\n",
    "                    alt_size=(10,6),\n",
    "                    sharex=sharex,\n",
    "                    sharey=sharey,\n",
    "                    commonlabel=commonlabel)\n",
    "\n",
    "dict_cyc_vis = dict_visualization\n",
    "utils.plot_digraphs_and_cycles(list(dict_cyc_vis.values()), list(dict_cyc_vis.keys()), commonlabel,\n",
    "                    alt_size=(13,5), arrowsize=14, font_size=10, node_size=250, no_cycles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-beast",
   "metadata": {},
   "source": [
    "As expected, both algorithms identify the structure, but FCI only up to Markov Equivalence whereas NOTEARS manages to find the exact causal graph (however, there is no guarantee --- beginner's luck you might call it here).\n",
    "\n",
    "**To conclude we can use the available data in different, creative ways to find out about its origin, that is, the data generating SCM's causal graph - amazing!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-examination",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "complicated-spiritual",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-treaty",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "preceding-buffalo",
   "metadata": {},
   "source": [
    "#### Shoutout to the great organizers of this wonderful workshop, they have done an amazing job! `\\(*.*)/`\n",
    "\n",
    "Starting from the later afternoon, I will be available to answer any questions.\n",
    "Also, do not hesitate to contact me via mail, thanks for your time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-tobacco",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "narrow-helena",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "technical-original",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "asian-douglas",
   "metadata": {},
   "source": [
    "### [4] Bonus: We have the Graph. What do we do with it?\n",
    "\n",
    "Great. We have learned so much already.\n",
    "\n",
    "We have seen the different phenomena, seen how to formalize it within the SCM, and now even showed how we can get the underlying graph of the SCM --- *without actually performing any interventions ourselves, just from passive data.*\n",
    "\n",
    "Having the graph, as we know from Section [2] though, is only underlying the SCM.\n",
    "\n",
    "But what can we do with the graph? We can train a machine learning model to *effectively learn an SCM*.\n",
    "\n",
    "In the following, we will not actually learn an SCM in the interest of time and space, however, we will assume an SCM given (as before when we actually created one), and will ask the question.\n",
    "\n",
    "***Once we have the SCM, what can we answer?***\n",
    "\n",
    "Well, having the SCM means having the capabilities of producing the elements of reasoning from Section [2].\n",
    "\n",
    "Most often, however, we are interested in a *causal effect* i.e., how does $A$ really *influence* $B$?\n",
    "\n",
    "Formally, we can capture this with the Average Causal Effect (ACE), in the case of say binary $A,B$ we have\n",
    "\n",
    "$$\n",
    "ACE(A,B):= \\mathbb{E}[A|do(B=1)]-\\mathbb{E}[A|do(B=0)] = P(A=1|do(B=1))-P(A=1|do(B=0)).\n",
    "$$\n",
    "\n",
    "As you recognize, whether we have a learned SCM or the actual SCM, the ACE simply defines a difference between two different interventional distributions which we can easily acquire having the former. Done.\n",
    "\n",
    "#### [B.1] Complimenting the $do$-Calculus with Neural Networks\n",
    "\n",
    "*But say we did not have the SCM, only the graph. Then we don't know how to get say $P(A|do(B))$?*\n",
    "\n",
    "The surprising answer: No, we can *identify* $P(A|do(B))$ from purely observational data using our knowledge on the graph.\n",
    "\n",
    "The previous section covered *structure identification* whereas this is known as *effect identification*.\n",
    "\n",
    "The celebrated tool for this is Pearl's own $do$-calculus, which is a graphical-algebraic tool proven to be *complete* i.e., any effect tha can be identified will get an answer from $do$-calculus and if it cannot be identified, then $do$-calculus will also let you know.\n",
    "\n",
    "Let us look at the following example.\n",
    "\n",
    "The SCM $\\mathcal{M}$ is given with the structural equations (with standard normal noise terms)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "A &= f_A(U_A) = U_A \\\\\n",
    "B &= f_B(A,U_B) = A^2 + U_B \\\\\n",
    "C &= f_R(A,B,U_C) = A^2 + B^3 + U_C\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "then the implied graph is $A\\rightarrow \\{B,C\\}; B\\rightarrow C$ and $do$-calculus will reveal that\n",
    "\n",
    "$$\n",
    "p(C|do(B))=\\int p(C|A,B)p(A) dA\n",
    "$$\n",
    "\n",
    "where the r.h.s. are all observational, probabilistic terms that we can learn from empirical data following $p(A,B,C)$ (!) and we call this r.h.s. the *estimand* (an observational estimand of a causal quantity).\n",
    "\n",
    "More specifically, we can learn a neural net (or e.g. a sum-product network for tractability and probability guarantees) to estimate the components of the estimand and thus answer our causal query!\n",
    "\n",
    "Let's define the above SCM and then train a simple neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_data(N):\n",
    "    \"\"\"\n",
    "        N is the number of samples\n",
    "    \"\"\"\n",
    "    U_A = np.random.normal(0,1,(N,1))\n",
    "    U_B = np.random.normal(0,1,(N,1))\n",
    "    U_C = np.random.normal(0,1,(N,1))\n",
    "    A = U_A\n",
    "    B = A**2 + U_B\n",
    "    C = A**2 + B**2 + U_C\n",
    "    return np.hstack((A, B, C))\n",
    "df = pd.DataFrame(toy_data(N=1000), columns=[\"A\",\"B\", \"C\"])\n",
    "\n",
    "print(f\"Var(A)={np.var(df['A']):.2f}, Var(B)={np.var(df['B']):.2f}, Var(C)={np.var(df['C']):.2f}\")\n",
    "\n",
    "def toy_data_int_B0(N):\n",
    "    \"\"\"\n",
    "        N is the number of samples\n",
    "    \"\"\"\n",
    "    U_A = np.random.normal(0,1,(N,1))\n",
    "    U_B = np.random.normal(0,1,(N,1))\n",
    "    U_C = np.random.normal(0,1,(N,1))\n",
    "    A = U_A\n",
    "    B = np.zeros((N,1))\n",
    "    C = A**2 + B**2 + U_C\n",
    "    return np.hstack((A, B, C))\n",
    "df_int_B0 = pd.DataFrame(toy_data_int_B0(N=1000), columns=[\"A\",\"B\", \"C\"])\n",
    "\n",
    "\n",
    "fig,axs = plt.subplots(2,3,figsize=(10,6))\n",
    "sns.scatterplot(data=df, x='A', y='B', ax=axs[0,0])\n",
    "sns.scatterplot(data=df, x='A', y='C', ax=axs[0,1])\n",
    "sns.scatterplot(data=df, x='B', y='C', ax=axs[0,2])\n",
    "sns.scatterplot(data=df_int_B0, x='A', y='B', ax=axs[1,0])\n",
    "sns.scatterplot(data=df_int_B0, x='A', y='C', ax=axs[1,1])\n",
    "sns.scatterplot(data=df_int_B0, x='B', y='C', ax=axs[1,2])\n",
    "for a in axs.flatten():\n",
    "    a.set_box_aspect(1.)\n",
    "plt.suptitle(\"Top Row shows Observational distributions derived from p(A,B,C)\\nBottom Row shows distributions derived from interventional distribution p(A,B,C|do(B=0))\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-jurisdiction",
   "metadata": {},
   "source": [
    "We are going to try to compute the interventional distribution $p(C|do(B=0))$ (the lower three plots) using our estimand.\n",
    "\n",
    "We will fit two separate neural nets, one for $p(C|B,A)$ and one for $p(A)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "        Simple Multi-Layer Perceptron, MLP with one hidden layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, len_inputs):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(len_inputs, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net_c_given_ba = NeuralNetwork(len_inputs=2)\n",
    "net_a = NeuralNetwork(len_inputs=1)\n",
    "neural_nets = [(net_c_given_ba, \"f(C; B, A)\"), (net_a, \"f(A)\")]\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.float()\n",
    "        self.y = y.float()\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "dataset_c_given_ba = Dataset(torch.tensor(df[[\"B\", \"A\"]].values), torch.tensor(df[\"C\"])[:,None])\n",
    "dataset_a = Dataset(torch.ones_like(torch.tensor(df[\"A\"])[:,None]), torch.tensor(df[\"A\"])[:,None])\n",
    "    \n",
    "dl_c_given_ba = torch.utils.data.DataLoader(dataset_c_given_ba, batch_size=10, shuffle=True, num_workers=1)\n",
    "dl_a = torch.utils.data.DataLoader(dataset_a, batch_size=10, shuffle=True, num_workers=1)\n",
    "dataloaders = [dl_c_given_ba, dl_a]\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "epochs = 100\n",
    "results = {}\n",
    "for ind, (net,desc) in enumerate(neural_nets):\n",
    "    loss_curve = []\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.0001)\n",
    "    for e in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "        current_loss = 0.\n",
    "        for i, data in enumerate(dataloaders[ind]):\n",
    "\n",
    "            inputs, targets = data\n",
    "            inputs = inputs[:, None]\n",
    "            targets = targets[:, None]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = net(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_curve.append(loss)\n",
    "    results.update({desc: loss_curve})\n",
    "\n",
    "fig, axs = plt.subplots(1,2, sharex=True)\n",
    "axs[0].plot(range(epochs), results[\"f(C; B, A)\"], label=\"f(C; B, A)\")\n",
    "axs[1].plot(range(epochs), results[\"f(A)\"], label=\"f(A)\")\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "plt.suptitle(\"Loss Curves, Mean-Squared Error\")\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(12,3))\n",
    "axs[0].scatter(dataset_c_given_ba.X[:,0],dataset_c_given_ba.y,label=\"Ground Truth\")\n",
    "axs[0].scatter(dataset_c_given_ba.X[:,0],net_c_given_ba(dataset_c_given_ba.X).detach().numpy(),label=\"NN f(C; B, A)\", color=\"orange\")\n",
    "axs[1].scatter(dataset_c_given_ba.X[:,1],dataset_c_given_ba.y,label=\"Ground Truth\")\n",
    "axs[1].scatter(dataset_c_given_ba.X[:,1],net_c_given_ba(dataset_c_given_ba.X).detach().numpy(),label=\"NN f(C; B, A)\", color=\"orange\")\n",
    "axs[2].scatter(dataset_a.X,dataset_a.y,label=\"Ground Truth\")\n",
    "axs[2].scatter(dataset_a.X,net_a(dataset_a.X).detach().numpy(),label=\"NN f(A)\", color=\"orange\")\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "axs[2].legend()\n",
    "plt.suptitle(\"Predictions of Empirical Distribution p(A,B,C)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-emission",
   "metadata": {},
   "source": [
    "As we see, our neural net is capable of approximating the content of the desired distribution. However, note that here we just considered a simple, discriminative setting i.e., if we actually want to have the distribution (capable of simulation), then we should deploy our Neural Net(s) within e.g. Normalizing Flows (NF for short). If we were to use graph neural networks (GNN for short), then a natural candidate would be the variational graph-autoencoder (VGAE for short). But this we keep for another tutorial.\n",
    "\n",
    "##### On another note, the amazing [Petar Veličković](https://petar-v.com/) will hold the second tutorial tomorrow on GNNs. We actually have some joint work, joining the forces of Causality and GNNs, so if you are interested, then please have a look at: https://matej-zecevic.de/2021/255/relating-GNN-to-SCM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-packaging",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "extra-fighter",
   "metadata": {},
   "source": [
    "#### [B.2] Bounding Causal Effects from Causal Assumptions\n",
    "\n",
    "In this final (bonus) subsection of this tutorial, we will consider an advanced topic in causal inference, where we are again given only structural knowledge on the graph alongside our data, and we try to *bound* the causal effect.\n",
    "\n",
    "The following example is based on Zhang & Bareinboim 2017, ZB17 in short.\n",
    "\n",
    "We define a non-Markovian SCM i.e., $U1$ is both parent to $X$ and $Y$, as\n",
    "\n",
    "$$\n",
    "\\mathcal{M} = \\langle \\mathbf{U},\\mathbf{V},\\mathcal{F},P(\\mathbf{U}) \\rangle\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\\mathbf{U}=\\{U_1, U_2\\}, \\mathbf{V}=\\{X, Y\\}, \\mathcal{F}=\\{f_X=U_1, f_Y=X\\oplus U_1 \\oplus U2\\}$$\n",
    "\n",
    "and $P(\\mathbf{U})=P(U_1)*P(U_2)$ with $P(U_1)=P(U_2)\\sim B(.9)$, where $\\oplus$ denotes logical xor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(1e7)\n",
    "p1 = p2 = 0.9\n",
    "\n",
    "def SCM(N,p1,p2):\n",
    "\n",
    "    # SCM definition as above\n",
    "    U1 = np.random.binomial(1, p1, size=N)\n",
    "    U2 = np.random.binomial(1, p2, size=N)\n",
    "    X = U1\n",
    "    Y = np.logical_xor(np.logical_xor(X, U1), U2)\n",
    "    \n",
    "    #reshape\n",
    "    X = X.reshape(-1,1)\n",
    "    Y = Y.reshape(-1,1)\n",
    "    D = np.hstack((X,Y)) # data stack\n",
    "    \n",
    "    return D\n",
    "\n",
    "D = SCM(N, p1, p2) # this is the observational data\n",
    "df = pd.DataFrame(D, columns=[\"X\",\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-contrast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "brave-wealth",
   "metadata": {},
   "source": [
    "Now, let's compute all the probabilities $p_{ij}:=P(X=i, Y=j)$ of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_probs(df, N):\n",
    "\n",
    "    p00 = len(df[(df.X == 0) & (df.Y == 0)])\n",
    "    p01 = len(df[(df.X == 0) & (df.Y == 1)])\n",
    "    p10 = len(df[(df.X == 1) & (df.Y == 0)])\n",
    "    p11 = len(df[(df.X == 1) & (df.Y == 1)])\n",
    "\n",
    "    ps = [p00, p01, p10, p11]\n",
    "    ps = [x/N for x in ps]\n",
    "    \n",
    "    return ps\n",
    "\n",
    "ps = joint_probs(df, N)\n",
    "\n",
    "assert(np.allclose(sum(ps), 1.))\n",
    "\n",
    "print(f'p(X=0,Y=0)={ps[0]:.3f}\\np(X=0,Y=1)={ps[1]:.3f}\\np(X=1,Y=0)={ps[2]:.3f}\\np(X=1,Y=1)={ps[3]:.3f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-pleasure",
   "metadata": {},
   "source": [
    "Next we will check their precise numbers regarding causal effect $\\mu_x = \\mathbb{E}[Y|do(x)]$.\n",
    "Obviously, for the non-Markovian variant (where $U_1$ is a confounder, but note observed!) the effect is not\n",
    "identifiable, meaning that we can have another SCM $\\mathcal{M}'$ which has a different $\\mu_x$.\n",
    "\n",
    "First, we will intervene $\\mathcal{M}$ to create $\\mathcal{M}'$.\n",
    "\n",
    "Second, we simulate $\\mathcal{M}'$ to get to the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCM_intervened(N,p1,p2, interv):\n",
    "\n",
    "    U1 = np.random.binomial(1, p1, size=N)\n",
    "    U2 = np.random.binomial(1, p2, size=N)\n",
    "    X = np.repeat(interv, N)\n",
    "    Y = np.logical_xor(np.logical_xor(X, U1), U2)\n",
    "    \n",
    "    #reshape\n",
    "    X = X.reshape(-1,1)\n",
    "    Y = Y.reshape(-1,1)\n",
    "    D = np.hstack((X,Y)) # data\n",
    "    \n",
    "    return D\n",
    "\n",
    "D_i0 = SCM_intervened(N, p1, p2, interv=0) # this is intervened do(X=0)\n",
    "D_i1 = SCM_intervened(N, p1, p2, interv=1)\n",
    "\n",
    "ps_i0 = joint_probs(pd.DataFrame(D_i0, columns=[\"X\",\"Y\"]), N)\n",
    "ps_i1 = joint_probs(pd.DataFrame(D_i1, columns=[\"X\",\"Y\"]), N)\n",
    "\n",
    "assert(np.allclose(sum(ps_i0), 1.))\n",
    "assert(np.allclose(sum(ps_i1), 1.))\n",
    "\n",
    "print(f'Intervention do(X=0):\\n p(X=0,Y=0)={ps_i0[0]:.3f}\\np(X=0,Y=1)={ps_i0[1]:.3f}\\np(X=1,Y=0)={ps_i0[2]:.3f}\\np(X=1,Y=1)={ps_i0[3]:.3f}\\n')\n",
    "print(f'Intervention do(X=1):\\n p(X=0,Y=0)={ps_i1[0]:.3f}\\np(X=0,Y=1)={ps_i1[1]:.3f}\\np(X=1,Y=0)={ps_i1[2]:.3f}\\np(X=1,Y=1)={ps_i1[3]:.3f}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-ballet",
   "metadata": {},
   "source": [
    "And indeed our result is correct, if you look at what we have just computed.\n",
    "\n",
    "Remember $\\mu_x = \\mathbb{E}[Y|do(X=x)] = \\sum_y y*p(Y|do(X=x))$. Since $y\\in\\{0,1\\}$ we have that $\\mu_x = p(Y=1|do(X=x))$\n",
    "\n",
    "And $\\mu_0 = 0.18$ are $\\mu_1 = 0.82$ respectively --- these are our _ground truth answers_ in this case.\n",
    "\n",
    "\n",
    "Next, we start looking into the actual interesting stuff namely the bounds. We don't have the intervened SCM $\\mathcal{M}'$ actually (we know it now just for the sake of tutorial) of course but only an empirical part of $P_{\\mathcal{M}}(X,Y)$.\n",
    "\n",
    "The bound in ZB17 is given by $$\\mathbb{E}[Y|do(X=0)] \\geq l := p_{01}, \\quad \\mathbb{E}[Y|do(X=1)] \\geq l := p_{11}$$ \n",
    "\n",
    "and \n",
    "\n",
    "$$\\mathbb{E}[Y|do(X=0)] \\leq h := l + p_{10} + p_{11}, \\quad \\mathbb{E}[Y|do(X=1)] \\leq h := l + p_{00} + p_{01}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bounds(ps):\n",
    "\n",
    "    l_0 = ps[1]\n",
    "    l_1 = ps[3]\n",
    "\n",
    "    h_0 = l_0 + ps[2] + ps[3]\n",
    "    h_1 = l_1 + ps[0] + ps[1]\n",
    "    \n",
    "    return (l_0, h_0), (l_1, h_1)\n",
    "\n",
    "(l_0, h_0), (l_1, h_1) = compute_bounds(ps)\n",
    "\n",
    "print(f'l_0 = {l_0:.3f} <= E[Y|do(X=0)]={ps_i0[1]:.3f} <= h_0 = {h_0:.3f}')\n",
    "print(f'l_1 = {l_1:.3f} <= E[Y|do(X=1)]={ps_i1[3]:.3f} <= h_1 = {h_1:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-password",
   "metadata": {},
   "source": [
    "Now let's plot the bounds tightness as a function of the number of samples $K$ from $P_M(X,Y)$ we get.\n",
    "\n",
    "Since we need the exact probabilities $P_{\\mathcal{M}}$ but have only approximations, it is good to see when the bound \"converges\" to see which number of samples, $K$, suffices to have the bound be intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_0 = []\n",
    "ts_1 = []\n",
    "Ks = [1, 10, 50, 100, 500, 1e4, 1e5, 1e6]\n",
    "for K in Ks:\n",
    "    assert(N >= K)\n",
    "    ps = joint_probs(df[:int(K)], K)\n",
    "    assert(np.allclose(sum(ps), 1.))\n",
    "    (l_0, h_0), (l_1, h_1) = compute_bounds(ps)\n",
    "    t_0 = h_0-l_0 # \"tightness of bound\"\n",
    "    t_1 = h_1-l_1\n",
    "    ts_0.append(t_0)\n",
    "    ts_1.append(t_1)\n",
    "    #print(f'(l_0,h_0)=({l_0:.3f},{h_0:.3f})\\t (l_1,h_1)=({l_1:.3f},{h_1:.3f})')\n",
    "\n",
    "plt.plot(Ks, ts_0, label=\"do(X=0)\")\n",
    "plt.plot(Ks, ts_1, label=\"do(X=1)\")\n",
    "plt.legend()\n",
    "plt.title(\"Tightness of Bound reduces with more samples\")\n",
    "plt.gca().set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-startup",
   "metadata": {},
   "source": [
    "Pretty cool! \n",
    "\n",
    "We don't know anything about the structural equations $\\mathcal{F}$ in this bound just the base graph implied by the underlying SCM, yet, for $do(X=0)$ we have a very tight bound i.e., we knew a-priori what kind of causal effect to expect in this practical setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-carrier",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "corrected-ethernet",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "internal-inventory",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-apollo",
   "metadata": {},
   "source": [
    "### This also concludes the Bonus section. I hope you had fun, stay curious, and c ya! `\\(*.*)/`\n",
    "\n",
    "#### Democritus wrote, “I would rather discover one true cause than gain the Kingdom of Persia.”\n",
    "\n",
    "##### Pearl said, \"As X-rays are to the surgeon, graphs are for causation.\"\n",
    "\n",
    "*Matej swiftly adapts to, ”As graphs are to the causality, causal nets are for AI.”*\n",
    "\n",
    "This was my final, personal message. Thanks to all the participants, thanks to all the organizers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-allergy",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blond-fancy",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "danish-innocent",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fee2154a520057aba9582f4676fb1abe67f001c6ddbbcd2e74f2a5bad9d5b013"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
